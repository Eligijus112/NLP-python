{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the needed libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration tracking \n",
    "from tqdm import tqdm \n",
    "\n",
    "# Regular expressions\n",
    "import re\n",
    "\n",
    "# Typehinting \n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the text to tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"NLP in Python is fun and very well documented. Let's get started!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(x: str) -> str:\n",
    "    \"\"\"\n",
    "    Function that preprocess the text before tokenization\n",
    "\n",
    "    Args:\n",
    "        x (str): text to preprocess\n",
    "\n",
    "    Returns:\n",
    "        str: preprocessed text\n",
    "    \"\"\" \n",
    "    # Create whitespaces around punctuation\n",
    "    x = re.sub(r'([.,!?;:])', r' \\1 ', x)\n",
    "\n",
    "    # Returns the text \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP in Python is fun and very well documented .  Let's get started ! \n"
     ]
    }
   ],
   "source": [
    "text_preprocessed = preprocess_text(text)\n",
    "print(text_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word_index(x: str) -> Tuple[dict, dict]: \n",
    "    \"\"\"\n",
    "    Function that scans a given text and creates two dictionaries:\n",
    "    - word2idx: dictionary mapping words to integers\n",
    "    - idx2word: dictionary mapping integers to words\n",
    "\n",
    "    Args:\n",
    "        x (str): text to scan\n",
    "\n",
    "    Returns:\n",
    "        Tuple[dict, dict]: word2idx and idx2word dictionaries\n",
    "    \"\"\"\n",
    "    # Spliting the text into words\n",
    "    words = x.split()\n",
    "\n",
    "    # Creating the word2idx dictionary \n",
    "    word2idx = {}\n",
    "    for word in words: \n",
    "        if word not in word2idx: \n",
    "            # The len(word2idx) will always ensure that the \n",
    "            # new index is 1 + the length of the dictionary so far\n",
    "            word2idx[word] = len(word2idx)\n",
    "\n",
    "    # Adding the <UNK> token to the dictionary; This token will be used \n",
    "    # on new texts that were not seen during training.\n",
    "    # It will have the last index. \n",
    "    word2idx['<UNK>'] = len(word2idx)\n",
    "\n",
    "    # Reversing the above dictionary and creating the idx2word dictionary\n",
    "    idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "\n",
    "    # Returns the dictionaries\n",
    "    return word2idx, idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the word2idx and idx2word dictionaries\n",
    "word2idx, idx2word = create_word_index(text_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NLP': 0,\n",
       " 'in': 1,\n",
       " 'Python': 2,\n",
       " 'is': 3,\n",
       " 'fun': 4,\n",
       " 'and': 5,\n",
       " 'very': 6,\n",
       " 'well': 7,\n",
       " 'documented': 8,\n",
       " '.': 9,\n",
       " \"Let's\": 10,\n",
       " 'get': 11,\n",
       " 'started': 12,\n",
       " '!': 13,\n",
       " '<UNK>': 14}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'NLP',\n",
       " 1: 'in',\n",
       " 2: 'Python',\n",
       " 3: 'is',\n",
       " 4: 'fun',\n",
       " 5: 'and',\n",
       " 6: 'very',\n",
       " 7: 'well',\n",
       " 8: 'documented',\n",
       " 9: '.',\n",
       " 10: \"Let's\",\n",
       " 11: 'get',\n",
       " 12: 'started',\n",
       " 13: '!',\n",
       " 14: '<UNK>'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function that splits a text into tokens \n",
    "def text2tokens(x: str, word2idx: dict) -> list: \n",
    "    \"\"\"\n",
    "    Function that tokenizes a text\n",
    "\n",
    "    Args:\n",
    "        x (str): text to tokenize\n",
    "        word2idx (dict): word2idx dictionary\n",
    "\n",
    "    Returns:\n",
    "        list: list of tokens\n",
    "    \"\"\"\n",
    "    # Spliting the text into words\n",
    "    words = x.split()\n",
    "\n",
    "    # Creating the list of tokens\n",
    "    tokens = []\n",
    "    for word in words: \n",
    "        # The bellow line searches for the word in the word2idx dictionary\n",
    "        # and returns the index of the word. If the word is not found,\n",
    "        # it returns the index of the <UNK> token\n",
    "        tokens.append(word2idx.get(word, word2idx['<UNK>']))\n",
    "\n",
    "    # Returns the list of tokens\n",
    "    return tokens\n",
    "\n",
    "# Defining a function that converts the tokens to text \n",
    "def tokens2text(x: list, idx2word: dict) -> str:\n",
    "    \"\"\"\n",
    "    Function that converts tokens to text\n",
    "\n",
    "    Args:\n",
    "        x (list): list of tokens\n",
    "        idx2word (dict): idx2word dictionary\n",
    "\n",
    "    Returns:\n",
    "        str: text\n",
    "    \"\"\"\n",
    "    # Creating the list of words\n",
    "    words = []\n",
    "    for idx in x: \n",
    "        # The bellow line searches for the index in the idx2word dictionary\n",
    "        # and returns the word. If the index is not found,\n",
    "        # it returns the <UNK> token\n",
    "        words.append(idx2word.get(idx, '<UNK>'))\n",
    "\n",
    "    # Returns the text\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the text2tokens function to the text\n",
    "tokens_seq = text2tokens(text_preprocessed, word2idx)\n",
    "\n",
    "# Transforming the tokens back to text\n",
    "text_seq = tokens2text(tokens_seq, idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"NLP in Python is fun and very well documented . Let's get started !\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      " As I said ,  Python is a very good tool for NLP\n",
      "Tokens:\n",
      " [14, 14, 14, 14, 2, 3, 14, 6, 14, 14, 14, 0]\n",
      "Text:\n",
      " <UNK> <UNK> <UNK> <UNK> Python is <UNK> very <UNK> <UNK> <UNK> NLP\n"
     ]
    }
   ],
   "source": [
    "# Putting everything together with a new text\n",
    "text = \"As I said, Python is a very good tool for NLP\"\n",
    "\n",
    "# Preprocessing the text\n",
    "text_preprocessed = preprocess_text(text)\n",
    "\n",
    "# Applying the text2tokens function to the text\n",
    "tokens_seq = text2tokens(text_preprocessed, word2idx)\n",
    "\n",
    "# Transforming the tokens back to text\n",
    "text_seq = tokens2text(tokens_seq, idx2word)\n",
    "\n",
    "print(f\"Original text:\\n {text_preprocessed}\")\n",
    "print(f\"Tokens:\\n {tokens_seq}\")\n",
    "print(f\"Text:\\n {text_seq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
