{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the needed packages\n",
    "import torch \n",
    "from torch import nn\n",
    "import pandas as pd \n",
    "import re \n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "# Spliting the data into train and test\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data \n",
    "d = pd.read_csv('input/Tweets.csv')\n",
    "\n",
    "# Keeping the needed columns \n",
    "d = d[['airline_sentiment', 'text']]\n",
    "\n",
    "# Leaving only the positive and the negative sentiments \n",
    "d = d[d['airline_sentiment'].isin(['positive', 'negative'])]\n",
    "\n",
    "# Encoding the sentiments that the negative will be 1 and the positive 0\n",
    "d['airline_sentiment'] = d['airline_sentiment'].apply(lambda x: 0 if x == 'positive' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(x: str) -> str:\n",
    "    \"\"\"\n",
    "    Function that preprocess the text before tokenization\n",
    "\n",
    "    Args:\n",
    "        x (str): text to preprocess\n",
    "\n",
    "    Returns:\n",
    "        str: preprocessed text\n",
    "    \"\"\" \n",
    "    # Create whitespaces around punctuation\n",
    "    x = re.sub(r'([.,!?;:])', r' \\1 ', x)\n",
    "\n",
    "    # Returns the text \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (9232, 2)\n",
      "Test shape: (2309, 2)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing the text\n",
    "d['text'] = d['text'].apply(preprocess_text)\n",
    "\n",
    "# Spliting to train test \n",
    "train, test = train_test_split(d, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reseting the indexes \n",
    "train.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f'Train shape: {train.shape}')\n",
    "print(f'Test shape: {test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word_index(x: str, shift_for_padding: bool = False) -> Tuple[dict, dict]: \n",
    "    \"\"\"\n",
    "    Function that scans a given text and creates two dictionaries:\n",
    "    - word2idx: dictionary mapping words to integers\n",
    "    - idx2word: dictionary mapping integers to words\n",
    "\n",
    "    Args:\n",
    "        x (str): text to scan\n",
    "        shift_for_padding (bool, optional): If True, the function will add 1 to all the indexes.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[dict, dict]: word2idx and idx2word dictionaries\n",
    "    \"\"\"\n",
    "    # Spliting the text into words\n",
    "    words = x.split()\n",
    "\n",
    "    # Creating the word2idx dictionary \n",
    "    word2idx = {}\n",
    "    for word in words: \n",
    "        if word not in word2idx: \n",
    "            # The len(word2idx) will always ensure that the \n",
    "            # new index is 1 + the length of the dictionary so far\n",
    "            word2idx[word] = len(word2idx)\n",
    "\n",
    "    # Adding the <UNK> token to the dictionary; This token will be used \n",
    "    # on new texts that were not seen during training.\n",
    "    # It will have the last index. \n",
    "    word2idx['<UNK>'] = len(word2idx)\n",
    "\n",
    "    if shift_for_padding:\n",
    "        # Adding 1 to all the indexes; \n",
    "        # The 0 index will be reserved for padding\n",
    "        word2idx = {k: v + 1 for k, v in word2idx.items()}\n",
    "\n",
    "    # Reversing the above dictionary and creating the idx2word dictionary\n",
    "    idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "\n",
    "    # Returns the dictionaries\n",
    "    return word2idx, idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the vocabulary is: 15572\n"
     ]
    }
   ],
   "source": [
    "# Joining all the texts into one string\n",
    "text = ' '.join(train['text'].values)\n",
    "\n",
    "# Creating the word2idx and idx2word dictionaries\n",
    "word2idx, idx2word = create_word_index(text, shift_for_padding=True)\n",
    "\n",
    "# Printing the size of the vocabulary\n",
    "print(f'The size of the vocabulary is: {len(word2idx)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9232.000000\n",
       "mean       21.295494\n",
       "std         7.311373\n",
       "min         2.000000\n",
       "25%        16.000000\n",
       "50%        23.000000\n",
       "75%        27.000000\n",
       "max        43.000000\n",
       "Name: seq_len, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each row in the train and test set, we will create a list of integers\n",
    "# that will represent the words in the text\n",
    "train['text_int'] = train['text'].apply(lambda x: [word2idx.get(word, word2idx['<UNK>']) for word in x.split()])\n",
    "test['text_int'] = test['text'].apply(lambda x: [word2idx.get(word, word2idx['<UNK>']) for word in x.split()])\n",
    "\n",
    "# Calculating the length of sequences in the train set \n",
    "train['seq_len'] = train['text_int'].apply(lambda x: len(x))\n",
    "\n",
    "# Describing the length of the sequences\n",
    "train['seq_len'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>text_int</th>\n",
       "      <th>seq_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@USAirways Another dead end .   They only hand...</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 5, 6, ...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@USAirways #2066 .  Was on plane from PBI to C...</td>\n",
       "      <td>[1, 26, 5, 27, 28, 29, 30, 31, 32, 33, 34, 35,...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>@USAirways waiting for bags now over 25min in ...</td>\n",
       "      <td>[1, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 49]</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>@USAirways Never heard back ,  but this would ...</td>\n",
       "      <td>[1, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@united Thanks !</td>\n",
       "      <td>[83, 84, 49]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9227</th>\n",
       "      <td>1</td>\n",
       "      <td>@AmericanAir she should not only get a refund ...</td>\n",
       "      <td>[190, 293, 267, 210, 7, 223, 41, 797, 64, 982,...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9228</th>\n",
       "      <td>1</td>\n",
       "      <td>@SouthwestAir I need updates on my flights 464...</td>\n",
       "      <td>[239, 19, 243, 881, 28, 74, 533, 15558, 162, 1...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9229</th>\n",
       "      <td>0</td>\n",
       "      <td>Lovely !  RT @JetBlue :  Our fleet’s on fleek ...</td>\n",
       "      <td>[14321, 49, 4479, 134, 68, 545, 15560, 28, 547...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9230</th>\n",
       "      <td>1</td>\n",
       "      <td>@united Okay thanks if you could please update...</td>\n",
       "      <td>[83, 5876, 137, 522, 115, 71, 360, 87, 14, 5, ...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9231</th>\n",
       "      <td>1</td>\n",
       "      <td>@USAirways IS THIS RINGLING BROTHERS BARNUM AN...</td>\n",
       "      <td>[1, 1414, 4731, 15562, 15563, 15564, 1098, 155...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9232 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      airline_sentiment                                               text  \\\n",
       "0                     1  @USAirways Another dead end .   They only hand...   \n",
       "1                     1  @USAirways #2066 .  Was on plane from PBI to C...   \n",
       "2                     1  @USAirways waiting for bags now over 25min in ...   \n",
       "3                     1  @USAirways Never heard back ,  but this would ...   \n",
       "4                     0                                  @united Thanks !    \n",
       "...                 ...                                                ...   \n",
       "9227                  1  @AmericanAir she should not only get a refund ...   \n",
       "9228                  1  @SouthwestAir I need updates on my flights 464...   \n",
       "9229                  0  Lovely !  RT @JetBlue :  Our fleet’s on fleek ...   \n",
       "9230                  1  @united Okay thanks if you could please update...   \n",
       "9231                  1  @USAirways IS THIS RINGLING BROTHERS BARNUM AN...   \n",
       "\n",
       "                                               text_int  seq_len  \n",
       "0     [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 5, 6, ...       29  \n",
       "1     [1, 26, 5, 27, 28, 29, 30, 31, 32, 33, 34, 35,...       31  \n",
       "2       [1, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 49]       12  \n",
       "3     [1, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70...       29  \n",
       "4                                          [83, 84, 49]        3  \n",
       "...                                                 ...      ...  \n",
       "9227  [190, 293, 267, 210, 7, 223, 41, 797, 64, 982,...       17  \n",
       "9228  [239, 19, 243, 881, 28, 74, 533, 15558, 162, 1...       22  \n",
       "9229  [14321, 49, 4479, 134, 68, 545, 15560, 28, 547...       15  \n",
       "9230  [83, 5876, 137, 522, 115, 71, 360, 87, 14, 5, ...       25  \n",
       "9231  [1, 1414, 4731, 15562, 15563, 15564, 1098, 155...       24  \n",
       "\n",
       "[9232 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(x: list, pad_length: int) -> list:\n",
    "    \"\"\"\n",
    "    Function that pads a given list of integers to a given length\n",
    "\n",
    "    Args:\n",
    "        x (list): list of integers to pad\n",
    "        pad_length (int): length to pad\n",
    "\n",
    "    Returns:\n",
    "        list: padded list of integers\n",
    "    \"\"\"\n",
    "    # Getting the length of the list\n",
    "    len_x = len(x)\n",
    "\n",
    "    # Checking if the length of the list is less than the pad_length\n",
    "    if len_x < pad_length: \n",
    "        # Padding the list with 0s\n",
    "        x = x + [0] * (pad_length - len_x)\n",
    "    else: \n",
    "        # Truncating the list to the desired length\n",
    "        x = x[:pad_length]\n",
    "\n",
    "    # Returning the padded list\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding the train and test sequences \n",
    "train['text_int'] = train['text_int'].apply(lambda x: pad_sequences(x, 30))\n",
    "test['text_int'] = test['text_int'].apply(lambda x: pad_sequences(x, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>text_int</th>\n",
       "      <th>seq_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@USAirways Another dead end .   They only hand...</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 5, 6, ...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@USAirways #2066 .  Was on plane from PBI to C...</td>\n",
       "      <td>[1, 26, 5, 27, 28, 29, 30, 31, 32, 33, 34, 35,...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>@USAirways waiting for bags now over 25min in ...</td>\n",
       "      <td>[1, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 49...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>@USAirways Never heard back ,  but this would ...</td>\n",
       "      <td>[1, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@united Thanks !</td>\n",
       "      <td>[83, 84, 49, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9227</th>\n",
       "      <td>1</td>\n",
       "      <td>@AmericanAir she should not only get a refund ...</td>\n",
       "      <td>[190, 293, 267, 210, 7, 223, 41, 797, 64, 982,...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9228</th>\n",
       "      <td>1</td>\n",
       "      <td>@SouthwestAir I need updates on my flights 464...</td>\n",
       "      <td>[239, 19, 243, 881, 28, 74, 533, 15558, 162, 1...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9229</th>\n",
       "      <td>0</td>\n",
       "      <td>Lovely !  RT @JetBlue :  Our fleet’s on fleek ...</td>\n",
       "      <td>[14321, 49, 4479, 134, 68, 545, 15560, 28, 547...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9230</th>\n",
       "      <td>1</td>\n",
       "      <td>@united Okay thanks if you could please update...</td>\n",
       "      <td>[83, 5876, 137, 522, 115, 71, 360, 87, 14, 5, ...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9231</th>\n",
       "      <td>1</td>\n",
       "      <td>@USAirways IS THIS RINGLING BROTHERS BARNUM AN...</td>\n",
       "      <td>[1, 1414, 4731, 15562, 15563, 15564, 1098, 155...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9232 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      airline_sentiment                                               text  \\\n",
       "0                     1  @USAirways Another dead end .   They only hand...   \n",
       "1                     1  @USAirways #2066 .  Was on plane from PBI to C...   \n",
       "2                     1  @USAirways waiting for bags now over 25min in ...   \n",
       "3                     1  @USAirways Never heard back ,  but this would ...   \n",
       "4                     0                                  @united Thanks !    \n",
       "...                 ...                                                ...   \n",
       "9227                  1  @AmericanAir she should not only get a refund ...   \n",
       "9228                  1  @SouthwestAir I need updates on my flights 464...   \n",
       "9229                  0  Lovely !  RT @JetBlue :  Our fleet’s on fleek ...   \n",
       "9230                  1  @united Okay thanks if you could please update...   \n",
       "9231                  1  @USAirways IS THIS RINGLING BROTHERS BARNUM AN...   \n",
       "\n",
       "                                               text_int  seq_len  \n",
       "0     [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 5, 6, ...       29  \n",
       "1     [1, 26, 5, 27, 28, 29, 30, 31, 32, 33, 34, 35,...       31  \n",
       "2     [1, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 49...       12  \n",
       "3     [1, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70...       29  \n",
       "4     [83, 84, 49, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...        3  \n",
       "...                                                 ...      ...  \n",
       "9227  [190, 293, 267, 210, 7, 223, 41, 797, 64, 982,...       17  \n",
       "9228  [239, 19, 243, 881, 28, 74, 533, 15558, 162, 1...       22  \n",
       "9229  [14321, 49, 4479, 134, 68, 545, 15560, 28, 547...       15  \n",
       "9230  [83, 5876, 137, 522, 115, 71, 360, 87, 14, 5, ...       25  \n",
       "9231  [1, 1414, 4731, 15562, 15563, 15564, 1098, 155...       24  \n",
       "\n",
       "[9232 rows x 4 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the torch model for sentiment classification \n",
    "class SentimentClassifier(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Class that defines the sentiment classifier model\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size + 1, embedding_dim)\n",
    "        self.rnn = nn.RNN(input_size=embedding_dim, hidden_size=1, batch_first=True)\n",
    "        self.fc = nn.Linear(1, 1)  # Output with a single neuron for binary classification\n",
    "        self.sigmoid = nn.Sigmoid()  # Sigmoid activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # Embedding layer\n",
    "        output, _ = self.rnn(x)  # RNN layer\n",
    "        # Use the hidden state from the last time step as the representation of the sequence\n",
    "        x = output[:, -1, :]\n",
    "\n",
    "        # Fully connected layer with a single neuron\n",
    "        x = self.fc(x) \n",
    "        \n",
    "        # Converting to probabilities\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        # Flattening the output\n",
    "        x = x.squeeze()\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Initiating the model \n",
    "model = SentimentClassifier(vocab_size=len(word2idx), embedding_dim=16)\n",
    "\n",
    "# Initiating the criterion and the optimizer\n",
    "criterion = nn.BCELoss() # Binary cross entropy loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the data loader \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # The x is named as text_int and the y as airline_sentiment\n",
    "        x = self.data.iloc[idx]['text_int']\n",
    "        y = self.data.iloc[idx]['airline_sentiment']\n",
    "        \n",
    "        # Converting the x and y to torch tensors\n",
    "        x = torch.tensor(x)\n",
    "        y = torch.tensor(y)\n",
    "\n",
    "        # Converting the y variable to float \n",
    "        y = y.float()\n",
    "\n",
    "        # Returning the x and y\n",
    "        return x, y\n",
    "    \n",
    "# Creating the train and test loaders\n",
    "train_loader = DataLoader(TextClassificationDataset(train), batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(TextClassificationDataset(test), batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.7827757836213162\n",
      "Epoch: 5, Loss: 0.5128291124497318\n",
      "Epoch: 10, Loss: 0.5100423388415142\n",
      "Epoch: 15, Loss: 0.5085798447313605\n",
      "Epoch: 20, Loss: 0.5045332652887259\n",
      "Epoch: 25, Loss: 0.4583601834039787\n",
      "Epoch: 30, Loss: 0.4495825650988978\n",
      "Epoch: 35, Loss: 0.4268802881859578\n"
     ]
    }
   ],
   "source": [
    "# Defining the number of epochs\n",
    "epochs = 10\n",
    "\n",
    "# Setting the model to train mode\n",
    "model.train()\n",
    "\n",
    "# Iterating through epochs\n",
    "for epoch in range(epochs):\n",
    "    # Initiating the total loss \n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = model(inputs)  # Forward pass\n",
    "\n",
    "        loss = criterion(outputs, labels)  # Compute the loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update the model's parameters\n",
    "\n",
    "        # Adding the loss to the total loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Calculating the average loss\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "    # Printing the loss every n epochs\n",
    "    if epoch % 5 == 0:\n",
    "        print(f'Epoch: {epoch}, Loss: {avg_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy is: 0.718492865562439\n"
     ]
    }
   ],
   "source": [
    "# Setting the model to eval model\n",
    "model.eval()\n",
    "\n",
    "# List to track the test acc \n",
    "total_correct = 0\n",
    "total_obs = 0\n",
    "\n",
    "# Iterating over the test set\n",
    "for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
    "    outputs = model(inputs)  # Forward pass\n",
    "\n",
    "    # Getting the number of correct predictions \n",
    "    correct = ((outputs > 0.5).float() == labels).float().sum()\n",
    "\n",
    "    # Getting the total number of predictions\n",
    "    total = labels.size(0)\n",
    "\n",
    "    # Updating the total correct and total observations\n",
    "    total_correct += correct\n",
    "    total_obs += total\n",
    "\n",
    "print(f'The test accuracy is: {total_correct / total_obs}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
